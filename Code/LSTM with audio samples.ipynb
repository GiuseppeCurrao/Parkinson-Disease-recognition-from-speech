{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# LSTM with audio samples\n","THIS CODE IS NOT RUN. WE PROPOSE THE CODE SINCE WE HAVE TALKED ABOUT IT IN THE REPORT BUT THE RESULTS ARE VERY POOR AND THE COMPUTATIONAL COMPLEXITY HIGH SO IT WAS NOT RUN IN COLAB.\n","\n","In this trial we decided to create a LSTM. The network take as input audio samples sampled with a frequency of 16 kHz."],"metadata":{"id":"v9-aHcr1WdaH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DylYqnSpWDFe"},"outputs":[],"source":["import numpy as np \n","import pandas as pd\n","import librosa\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm, tqdm_notebook; tqdm.pandas()\n","from sklearn.metrics import label_ranking_average_precision_score\n","from sklearn.model_selection import train_test_split\n","from scipy.io import wavfile\n","import csv\n","import random\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras import models\n","from IPython import display\n","import keras\n","from keras import backend as K\n","from tensorflow.keras.layers import Layer, InputSpec\n","from keras import initializers, regularizers, constraints, optimizers, layers\n","from keras.layers import (Dense, LSTM,Dropout)\n","from keras.callbacks import EarlyStopping\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","\n","seed = 123\n","tf.random.set_seed(seed)\n","np.random.seed(seed)\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["---\n","Here we define the function to create the data windows that then we pass to the network. Due to the limited capacity of the hardware we had to downsample the files at 16 kHz"],"metadata":{"id":"zCap-frQXgfE"}},{"cell_type":"code","source":["def create_windows(signal, window_size, hop_length):\n","    num_samples = len(signal)\n","    num_windows = 1 + (num_samples - window_size) // hop_length\n","    windows = np.zeros((num_windows, window_size))\n","\n","    for i in range(num_windows):\n","        start = i * hop_length\n","        end = start + window_size\n","        windows[i] = signal[start:end]\n","\n","    return windows\n","\n","def split_wav_in_windows(df):\n","    X = []\n","    window_size = 2048\n","    hop_length = 724\n","    for _,row in tqdm(df.iterrows()):\n","        y,sr = librosa.load(row.path, sr=16000)\n","        x = create_windows(y, window_size, hop_length)\n","        X.append(x.transpose())\n","    return X"],"metadata":{"id":"Fo2goC5bXkue"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","Open the csv and create the train, validation and test sets."],"metadata":{"id":"_qeBrG8oXoGe"}},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/DB/splitted_train12.csv\")\n","path = df[\"path\"].values\n","labels = df[\"label\"].values\n","\n","# Preprocess dataset and create validation sets\n","X1 = np.array(convert_wav_to_image(df))\n","\n","train_paths, test_paths, train_labels, test_labels = train_test_split(X1, labels, test_size=0.2, random_state=123)\n","train_paths, val_paths, train_labels, val_labels = train_test_split(train_paths, train_labels, test_size=0.15, random_state=123)"],"metadata":{"id":"a7PyOSHpXrFw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","Here we create the network."],"metadata":{"id":"9BpjSEpBYFkw"}},{"cell_type":"code","source":["input_shape=(2048,263)\n","model = keras.Sequential()\n","model.add(LSTM(96,input_shape=input_shape))\n","model.add(Dropout(0.3))\n","model.add(Dense(48, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()"],"metadata":{"id":"PW3g676pYJ2H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","We define the early stopping mechanism, the batch size and the number of epochs. Then, we fit the model."],"metadata":{"id":"guoURY9zYQj5"}},{"cell_type":"code","source":["learning_rate = 0.00001\n","optimizer = optimizers.Adam(learning_rate=learning_rate)\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=optimizer,\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"ievvweDeYUUH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size=80\n","epochs = 140\n","history = model.fit(train_paths, train_labels, epochs=epochs, batch_size = batch_size,\n","                    validation_data=(val_paths, val_labels), shuffle=False, callbacks=[early_stopping])"],"metadata":{"id":"Bsb84wXjYddq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","Plotting the loss function and the accuracy for both train and validation set."],"metadata":{"id":"_JGoJkrJYfeY"}},{"cell_type":"code","source":["loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_executed = early_stopping.stopped_epoch + 1\n","if epochs_executed != 1:\n","    rg = epochs_executed\n","else:\n","    rg = epochs    \n","plt.figure(figsize=(15,5))\n","plt.plot(range(rg), loss)\n","plt.plot(range(rg), val_loss)\n","plt.title('Loss over epochs', weight='bold', fontsize=22)\n","plt.xlabel('Epochs', fontsize=16)\n","plt.ylabel('Loss', fontsize=16)\n","plt.legend(['Training loss', 'Validation loss'], fontsize=16)\n","plt.show()\n","\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","plt.figure(figsize=(15,5))\n","plt.plot(range(rg), acc)\n","plt.plot(range(rg), val_acc)\n","plt.title('Accuracy over epochs', weight='bold', fontsize=22)\n","plt.xlabel('Epochs', fontsize=16)\n","plt.ylabel('Accuracy', fontsize=16)\n","plt.legend(['Training accuracy', 'Validation accuracy'], fontsize=16)\n","plt.show()"],"metadata":{"id":"SVaKmj9_YlBb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","Evaluating the model on the test set, calculating the confusion matrix, the f1-score, the recall and the accuracy"],"metadata":{"id":"_p17tLJFYscI"}},{"cell_type":"code","source":["test_loss, test_accuracy = model.evaluate(test_paths, test_labels)\n","\n","predictions = model.predict(test_paths)\n","\n","# Convert the predicted probabilities to class labels (0 or 1 in this case)\n","y_pred = (predictions > 0.5).astype(int)\n","\n","# Compute the confusion matrix\n","cm = confusion_matrix(test_labels, y_pred)\n","\n","plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Reds)\n","plt.title('Confusion Matrix')\n","plt.colorbar()\n","tick_marks = np.arange(2)\n","plt.xticks(tick_marks, ['Class 0', 'Class 1'])\n","plt.yticks(tick_marks, ['Class 0', 'Class 1'])\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","# Add text annotations within each cell\n","thresh = cm.max() / 2\n","for i in range(cm.shape[0]):\n","    for j in range(cm.shape[1]):\n","        plt.text(j, i, format(cm[i, j], 'd'),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","plt.show()\n","\n","#Printing the accuracy, the f1-score and the recall for each class\n","predicted_probabilities = predictions.flatten()\n","predicted_labels = (predicted_probabilities >= 0.5).astype(int)\n","\n","report = classification_report(test_labels, predicted_labels)\n","print(report)"],"metadata":{"id":"h3utDhL7cXNr"},"execution_count":null,"outputs":[]}]}